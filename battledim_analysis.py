"""
Smart Shygyn PRO v3 â€” BattLeDIM Real Analysis
ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑƒÑ‚ĞµÑ‡ĞµĞº L-Town (ĞšĞ¸Ğ¿Ñ€, 2019).

Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ. Ğ•ÑĞ»Ğ¸ SCADA Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ â€” Ğ¿Ñ€Ğ¾ÑĞ¸Ğ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ.
"""

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from typing import Optional, Dict, List, Tuple, Any

from data_loader import get_loader, KAZAKHSTAN_REAL_DATA


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ›Ğ“ĞĞ Ğ˜Ğ¢Ğœ Ğ”Ğ•Ğ¢Ğ•ĞšĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_baseline(scada_2018: pd.DataFrame) -> pd.DataFrame:
    """
    Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ baseline Ğ¿Ğ¾ 2018: Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ 5-Ğ¼Ğ¸Ğ½ ÑˆĞ°Ğ³Ğ° ÑÑƒÑ‚Ğ¾Ğº (0..287)
    Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ mean Ğ¸ std Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ´Ğ°Ñ‚Ñ‡Ğ¸ĞºÑƒ.
    """
    intra = (scada_2018.index.hour * 60 + scada_2018.index.minute) // 5
    rows = []
    for step in range(288):
        mask   = intra == step
        subset = scada_2018[mask]
        row: Dict[str, Any] = {"step": step}
        for col in scada_2018.columns:
            row[f"mean_{col}"] = float(subset[col].mean())
            row[f"std_{col}"]  = float(subset[col].std(ddof=1))
        rows.append(row)
    return pd.DataFrame(rows).set_index("step")


def detect_anomalies(scada_2019: pd.DataFrame,
                     baseline: pd.DataFrame,
                     z_threshold: float = 3.0,
                     min_sensors: int = 2) -> pd.Series:
    """
    Z-score Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ: Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ = Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚ ĞºĞ¾Ğ³Ğ´Ğ° â‰¥ min_sensors Ğ´Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ²
    Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ > z_threshold Ã— Ïƒ Ğ½Ğ¸Ğ¶Ğµ baseline.
    """
    intra = (scada_2019.index.hour * 60 + scada_2019.index.minute) // 5
    flags = pd.Series(False, index=scada_2019.index)

    for i, (ts, row) in enumerate(scada_2019.iterrows()):
        step = int(intra.iloc[i])
        if step not in baseline.index:
            continue
        triggered = 0
        for col in scada_2019.columns:
            m_col = f"mean_{col}"
            s_col = f"std_{col}"
            if m_col not in baseline.columns:
                continue
            mu  = baseline.loc[step, m_col]
            sig = baseline.loc[step, s_col]
            if sig < 1e-6:
                continue
            z = (mu - float(row[col])) / sig
            if z > z_threshold:
                triggered += 1
        if triggered >= min_sensors:
            flags.iloc[i] = True

    return flags


def compute_metrics(anomaly_flags: pd.Series,
                    leak_events: pd.DataFrame) -> Dict[str, Any]:
    """Precision / Recall / F1 / TTD."""
    if leak_events is None or len(leak_events) == 0:
        return {"precision": None, "recall": None, "f1": None,
                "ttd_hours": None, "detected": 0, "total": 0, "fp": 0}

    detected, ttd_list, det_ts = 0, [], set()

    for _, leak in leak_events.iterrows():
        try:
            t_s = pd.to_datetime(str(leak.get("Start") or leak.get("start", "")))
            t_e = pd.to_datetime(str(leak.get("End")   or leak.get("end",   "")))
        except Exception:
            continue
        w = anomaly_flags[(anomaly_flags.index >= t_s) &
                          (anomaly_flags.index <= t_e) & anomaly_flags]
        if len(w) > 0:
            detected += 1
            ttd_list.append(max(0, (w.index[0] - t_s).total_seconds() / 3600))
            det_ts.update(w.index.tolist())

    total = len(leak_events)
    all_anom = anomaly_flags[anomaly_flags].index
    fp = sum(1 for t in all_anom if t not in det_ts)
    tp = len(det_ts)

    recall    = detected / total if total > 0 else 0.0
    precision = tp / (tp + fp)   if (tp + fp) > 0 else 0.0
    f1        = 2 * precision * recall / (precision + recall + 1e-9)

    return {
        "precision": round(precision * 100, 1),
        "recall":    round(recall    * 100, 1),
        "f1":        round(f1        * 100, 1),
        "ttd_hours": round(float(np.mean(ttd_list)), 1) if ttd_list else None,
        "detected":  detected,
        "total":     total,
        "fp":        fp,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ ĞĞ¤Ğ˜ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _theme(dark: bool) -> Dict[str, str]:
    return {
        "bg":  "#0e1117" if dark else "white",
        "fg":  "#e2e8f0" if dark else "#2c3e50",
        "grd": "#2d3748" if dark else "#d0d0d0",
    }


def plot_pressure_with_detection(scada_2019: pd.DataFrame,
                                 anomaly_flags: pd.Series,
                                 leak_events: Optional[pd.DataFrame],
                                 sensor: str,
                                 day_range: Tuple[int, int],
                                 dark: bool) -> go.Figure:
    """Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ + ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ Ğ·Ğ¾Ğ½Ñ‹ ÑƒÑ‚ĞµÑ‡ĞµĞº + Ñ€Ğ¾Ğ¼Ğ±Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸."""
    t = _theme(dark)
    start = scada_2019.index[0] + pd.Timedelta(days=day_range[0] - 1)
    end   = scada_2019.index[0] + pd.Timedelta(days=day_range[1])
    mask  = (scada_2019.index >= start) & (scada_2019.index <= end)
    sl    = scada_2019[mask]
    af    = anomaly_flags[mask]

    fig = go.Figure()

    # Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
    fig.add_trace(go.Scatter(
        x=sl.index, y=sl[sensor],
        name=f"Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ â€” {sensor}",
        line=dict(color="#3b82f6", width=1.5),
        hovertemplate="<b>%{x}</b><br>%{y:.3f} Ğ±Ğ°Ñ€<extra></extra>"
    ))

    # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸
    apts = af[af]
    if len(apts) > 0 and sensor in sl.columns:
        fig.add_trace(go.Scatter(
            x=apts.index,
            y=sl.loc[sl.index.isin(apts.index), sensor],
            mode="markers",
            name="âš ï¸ Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°",
            marker=dict(color="#f59e0b", size=7, symbol="diamond"),
            hovertemplate="<b>%{x}</b><br>ĞĞ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ<extra></extra>"
        ))

    # Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ â€” ĞºÑ€Ğ°ÑĞ½Ñ‹Ğµ Ğ·Ğ¾Ğ½Ñ‹
    if leak_events is not None:
        shown_label = False
        for _, leak in leak_events.iterrows():
            try:
                t_s = pd.to_datetime(str(leak.get("Start") or ""))
                t_e = pd.to_datetime(str(leak.get("End")   or ""))
                if t_s > end or t_e < start:
                    continue
                fig.add_vrect(
                    x0=max(t_s, start), x1=min(t_e, end),
                    fillcolor="rgba(239,68,68,0.18)", layer="below", line_width=0,
                    annotation_text=f"#{int(leak.get('Leak #', '?'))} {leak.get('Pipe','?')}",
                    annotation_position="top left",
                    annotation_font_size=9, annotation_font_color="#ef4444"
                )
            except Exception:
                continue

    fig.update_layout(
        title=f"Ğ”Ğ°Ñ‚Ñ‡Ğ¸Ğº {sensor} | ğŸ”´ Ğ·Ğ¾Ğ½Ñ‹ = Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ | â¬¥ = Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Smart Shygyn",
        xaxis_title="Ğ’Ñ€ĞµĞ¼Ñ", yaxis_title="Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (Ğ±Ğ°Ñ€)",
        height=420, hovermode="x unified",
        plot_bgcolor=t["bg"], paper_bgcolor=t["bg"],
        font=dict(color=t["fg"], size=11),
        xaxis=dict(gridcolor=t["grd"], color=t["fg"]),
        yaxis=dict(gridcolor=t["grd"], color=t["fg"]),
        margin=dict(l=60, r=20, t=60, b=50),
        legend=dict(bgcolor="rgba(0,0,0,0)", orientation="h",
                    yanchor="bottom", y=-0.28, xanchor="center", x=0.5)
    )
    return fig


def plot_timeline(leak_events: pd.DataFrame,
                  anomaly_flags: pd.Series,
                  dark: bool) -> go.Figure:
    """Gantt-timeline 23 ÑƒÑ‚ĞµÑ‡ĞµĞº Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸."""
    t = _theme(dark)
    fig = go.Figure()

    for i, (_, leak) in enumerate(leak_events.iterrows()):
        try:
            t_s  = pd.to_datetime(str(leak.get("Start") or leak.get("start", "")))
            t_e  = pd.to_datetime(str(leak.get("End")   or leak.get("end",   "")))
            pipe = str(leak.get("Pipe", f"leak_{i+1}"))
            lnum = int(leak.get("Leak #", i + 1))
            flow = float(leak.get("Max Flow (L/s)", 1.0))
        except Exception:
            continue

        fig.add_trace(go.Scatter(
            x=[t_s, t_e, t_e, t_s, t_s],
            y=[i-.38, i-.38, i+.38, i+.38, i-.38],
            fill="toself", fillcolor="rgba(239,68,68,0.35)",
            line=dict(color="#ef4444", width=1),
            name="Ğ£Ñ‚ĞµÑ‡ĞºĞ°" if i == 0 else None,
            showlegend=(i == 0), legendgroup="leak",
            hovertemplate=(
                f"<b>Ğ£Ñ‚ĞµÑ‡ĞºĞ° #{lnum} â€” {pipe}</b><br>"
                f"{t_s:%Y-%m-%d %H:%M} â†’ {t_e:%Y-%m-%d %H:%M}<br>"
                f"Ğ Ğ°ÑÑ…Ğ¾Ğ´: {flow} Ğ»/Ñ<extra></extra>"
            )
        ))

        w = anomaly_flags[(anomaly_flags.index >= t_s) &
                          (anomaly_flags.index <= t_e) & anomaly_flags]
        if len(w) > 0:
            first = w.index[0]
            ttd   = max(0, (first - t_s).total_seconds() / 3600)
            fig.add_trace(go.Scatter(
                x=[first], y=[i],
                mode="markers",
                marker=dict(color="#f59e0b", size=11, symbol="star"),
                name="Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ" if i == 0 else None,
                showlegend=(i == 0), legendgroup="det",
                hovertemplate=(
                    f"<b>Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ #{lnum}</b><br>"
                    f"{first:%Y-%m-%d %H:%M}<br>"
                    f"TTD: {ttd:.1f} Ñ‡<extra></extra>"
                )
            ))

    labels = [str(r.get("Pipe", "?")) for _, r in leak_events.iterrows()]
    fig.update_yaxes(tickvals=list(range(len(leak_events))),
                     ticktext=labels, gridcolor=t["grd"], color=t["fg"])
    fig.update_layout(
        title="ğŸ—“ï¸ Timeline â€” 23 Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ L-Town 2019 | â­ = ĞºĞ¾Ğ³Ğ´Ğ° Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»",
        xaxis_title="Ğ”Ğ°Ñ‚Ğ°", height=620,
        plot_bgcolor=t["bg"], paper_bgcolor=t["bg"],
        font=dict(color=t["fg"], size=11),
        xaxis=dict(gridcolor=t["grd"], color=t["fg"]),
        margin=dict(l=110, r=20, t=60, b=50),
        legend=dict(bgcolor="rgba(0,0,0,0)", orientation="h",
                    yanchor="bottom", y=-0.07, xanchor="center", x=0.5)
    )
    return fig


def plot_baseline_vs_2019(baseline: pd.DataFrame,
                          scada_2019: pd.DataFrame,
                          sensor: str,
                          dark: bool) -> go.Figure:
    """Ğ¡ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ: baseline 2018 (mean Â± 2Ïƒ) vs ÑÑ€ĞµĞ´Ğ½ĞµĞµ 2019."""
    t = _theme(dark)
    times = [f"{h:02d}:{m:02d}" for h in range(24) for m in range(0, 60, 5)]

    m_col, s_col = f"mean_{sensor}", f"std_{sensor}"
    if m_col not in baseline.columns:
        return go.Figure()

    mu  = baseline[m_col].values
    sig = baseline[s_col].values

    intra_2019 = (scada_2019.index.hour * 60 + scada_2019.index.minute) // 5
    avg_2019 = np.array([
        scada_2019[sensor][intra_2019 == s].mean()
        if sensor in scada_2019.columns else np.nan
        for s in range(288)
    ])

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=times + times[::-1],
        y=list(mu + 2*sig) + list((mu - 2*sig)[::-1]),
        fill="toself", fillcolor="rgba(59,130,246,0.10)",
        line=dict(color="rgba(0,0,0,0)"),
        name="Baseline Â±2Ïƒ (2018)"
    ))
    fig.add_trace(go.Scatter(
        x=times, y=mu,
        name="Baseline 2018",
        line=dict(color="#3b82f6", width=2, dash="dash")
    ))
    fig.add_trace(go.Scatter(
        x=times, y=avg_2019,
        name="Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ 2019 (Ñ ÑƒÑ‚ĞµÑ‡ĞºĞ°Ğ¼Ğ¸)",
        line=dict(color="#ef4444", width=2)
    ))
    fig.update_layout(
        title=f"Ğ¡ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ â€” {sensor} | ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ½Ğ¸Ğ¶Ğµ ÑĞ¸Ğ½ĞµĞ¹ = ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ÑƒÑ‚ĞµÑ‡ĞºĞ°",
        xaxis_title="Ğ’Ñ€ĞµĞ¼Ñ ÑÑƒÑ‚Ğ¾Ğº", yaxis_title="Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (Ğ±Ğ°Ñ€)",
        height=380, hovermode="x unified",
        plot_bgcolor=t["bg"], paper_bgcolor=t["bg"],
        font=dict(color=t["fg"], size=11),
        xaxis=dict(gridcolor=t["grd"], color=t["fg"],
                   tickmode="array",
                   tickvals=times[::24], ticktext=times[::24]),
        yaxis=dict(gridcolor=t["grd"], color=t["fg"]),
        margin=dict(l=60, r=20, t=60, b=50),
        legend=dict(bgcolor="rgba(0,0,0,0)", orientation="h",
                    yanchor="bottom", y=-0.25, xanchor="center", x=0.5)
    )
    return fig


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ Ğ’ĞšĞ›ĞĞ”ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render_battledim_tab(dark_mode: bool = True):
    """ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ° BattLeDIM â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ."""
    loader = get_loader()
    status = loader.check_files_exist()
    have_2018 = status.get("scada_2018", False)
    have_2019 = status.get("scada_2019", False)

    st.markdown("## ğŸŒ BattLeDIM â€” Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑƒÑ‚ĞµÑ‡ĞµĞº L-Town (ĞšĞ¸Ğ¿Ñ€, 2019)")
    st.markdown(
        "ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Smart Shygyn Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ½Ğ° **Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…** Ğ²Ğ¾Ğ´Ğ¾Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ´Ğ° "
        "Ğ³. Ğ›Ğ¸Ğ¼Ğ°ÑÑĞ¾Ğ» â€” Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ Ñ‡Ñ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ ETH Zurich Ğ¸ MIT."
    )

    # â”€â”€ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ + ĞºĞ½Ğ¾Ğ¿ĞºĞ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    c1, c2 = st.columns([3, 1])
    with c1:
        if have_2018 and have_2019:
            st.success("âœ… SCADA 2018 Ğ¸ 2019 Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½")
        elif have_2019:
            st.warning("âš ï¸ Ğ•ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ 2019 SCADA â€” baseline Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸Ğ· ÑĞ°Ğ¼Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¼ĞµĞ½ĞµĞµ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾)")
        else:
            st.info("ğŸ“‚ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹")
    with c2:
        if st.button("ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ Zenodo", use_container_width=True):
            with st.spinner("Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ zenodo.org â€¦"):
                ok, msg = loader.download_dataset()
                if ok:
                    st.success(msg)
                    st.rerun()
                else:
                    st.error(msg)

    # â”€â”€ Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½ĞµÑ‚ â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not have_2018 and not have_2019:
        st.markdown("---")
        st.markdown("### Ğ§Ñ‚Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸:")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""
**ğŸ§  Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ÑƒÑ‚ĞµÑ‡ĞµĞº**
ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Z-score Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑÑ Ğ½Ğ° 365 Ğ´Ğ½ÑÑ…
Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… SCADA Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 2019 Ğ³Ğ¾Ğ´Ğ° Ğ¸
Ğ½Ğ°Ğ¹Ğ´Ñ‘Ñ‚ Ğ²ÑĞµ 23 Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚ĞµÑ‡ĞºĞ¸.
            """)
        with col2:
            st.markdown("""
**ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸**
Precision, Recall, F1-Score Ğ¸
ÑÑ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (TTD)
Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ğ· 23 Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑ‚ĞµÑ‡ĞµĞº.
            """)
        with col3:
            st.markdown("""
**ğŸ“ˆ Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸**
Timeline 23 ÑƒÑ‚ĞµÑ‡ĞµĞº, Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸, ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ
baseline 2018 vs Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ 2019.
            """)

        st.markdown("---")
        st.markdown(
            "**Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚:** [BattLeDIM 2020 Ğ½Ğ° Zenodo](https://zenodo.org/records/4017659) "
            "â€” DOI: 10.5281/zenodo.4017659  \n"
            "L-Town, Limassol, Cyprus: 782 ÑƒĞ·Ğ»Ğ° | 909 Ñ‚Ñ€ÑƒĞ± | 42.6 ĞºĞ¼ | 23 ÑƒÑ‚ĞµÑ‡ĞºĞ¸"
        )
        return   # â† Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼, Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼

    # â”€â”€ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")

    raw_2018 = loader.load_scada_2018()
    raw_2019 = loader.load_scada_2019()
    leaks_df = loader.load_leaks_2019()

    scada_2018 = raw_2018["pressures"].dropna(axis=1, how="all") if raw_2018 else None
    scada_2019 = raw_2019["pressures"].dropna(axis=1, how="all") if raw_2019 else None

    if scada_2019 is None:
        st.error("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ„Ğ°Ğ¹Ğ» 2019 SCADA. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ ÑĞ½Ğ¾Ğ²Ğ°.")
        return

    # Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚ 2018 â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 60 Ğ´Ğ½ĞµĞ¹ 2019 ĞºĞ°Ğº baseline
    if scada_2018 is None:
        cutoff = scada_2019.index[0] + pd.Timedelta(days=60)
        scada_2018 = scada_2019[scada_2019.index < cutoff]
        scada_2019 = scada_2019[scada_2019.index >= cutoff]
        st.warning("âš ï¸ Ğ¤Ğ°Ğ¹Ğ» 2018 Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ â€” baseline Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ¿Ğ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ 60 Ğ´Ğ½ÑĞ¼ 2019.")

    sensors = list(scada_2019.columns)

    # â”€â”€ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    net = loader.get_network_statistics()
    m1, m2, m3, m4, m5 = st.columns(5)
    with m1: st.metric("ğŸ”µ Ğ£Ğ·Ğ»Ğ¾Ğ²",      str(net["n_junctions"]))
    with m2: st.metric("ğŸ”´ Ğ¢Ñ€ÑƒĞ±",       str(net["n_pipes"]))
    with m3: st.metric("ğŸ“ Ğ”Ğ»Ğ¸Ğ½Ğ°",      f"{net['total_length_km']} ĞºĞ¼")
    with m4: st.metric("ğŸ“¡ Ğ”Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ²",   str(min(len(sensors), 33)))
    with m5: st.metric("ğŸš¨ Ğ£Ñ‚ĞµÑ‡ĞµĞº 2019","23")

    st.markdown("---")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞĞ›Ğ“ĞĞ Ğ˜Ğ¢Ğœ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    st.markdown("### ğŸ§  Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ÑƒÑ‚ĞµÑ‡ĞµĞº â€” Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Smart Shygyn")

    col_ctrl, col_kpi = st.columns([1, 2])
    with col_ctrl:
        z_thresh = st.slider("Z-score Ğ¿Ğ¾Ñ€Ğ¾Ğ³", 1.5, 5.0, 3.0, 0.1,
                             help="Ğ’Ñ‹ÑˆĞµ = Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³, Ğ½Ğ¸Ğ¶Ğµ recall")
        min_sens = st.slider("ĞœĞ¸Ğ½. Ğ´Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³Ğ¸",
                             1, min(5, len(sensors)), 2)

    with st.spinner("Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ baseline 2018 â€¦"):
        baseline = build_baseline(scada_2018)

    with st.spinner("Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ² 2019 â€¦"):
        anomaly_flags = detect_anomalies(
            scada_2019, baseline, z_thresh, min_sens
        )

    m = compute_metrics(anomaly_flags, leaks_df)

    with col_kpi:
        k1, k2, k3, k4 = st.columns(4)
        with k1:
            st.metric("ğŸ¯ Recall",
                      f"{m['recall']:.0f}%" if m['recall'] is not None else "â€”",
                      f"{m['detected']}/{m['total']} ÑƒÑ‚ĞµÑ‡ĞµĞº")
        with k2:
            st.metric("âœ… Precision",
                      f"{m['precision']:.0f}%" if m['precision'] is not None else "â€”",
                      f"FP: {m['fp']}")
        with k3:
            st.metric("âš–ï¸ F1",
                      f"{m['f1']:.0f}%" if m['f1'] is not None else "â€”")
        with k4:
            ttd = m['ttd_hours']
            st.metric("â± TTD",
                      f"{ttd:.1f} Ñ‡" if ttd is not None else "â€”",
                      "Time-to-Detect")

    st.markdown("---")

    # â”€â”€ Timeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ—“ï¸ Timeline â€” Ğ³Ğ´Ğµ Ğ¸ ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ ÑƒÑ‚ĞµÑ‡ĞºĞ¸")
    if leaks_df is not None:
        st.plotly_chart(plot_timeline(leaks_df, anomaly_flags, dark_mode),
                        use_container_width=True)
    else:
        st.info("Ğ¤Ğ°Ğ¹Ğ» Ñ Ğ¼ĞµÑ‚ĞºĞ°Ğ¼Ğ¸ ÑƒÑ‚ĞµÑ‡ĞµĞº (Leak_Labels) Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ â€” timeline Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½.")

    st.markdown("---")

    # â”€â”€ Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“ˆ Ğ”Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ñ‡Ğ¸Ğº + Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ")

    ca, cb = st.columns([1, 2])
    with ca:
        sensor = st.selectbox("Ğ”Ğ°Ñ‚Ñ‡Ğ¸Ğº", sensors[:20])
        max_d  = min(len(scada_2019) // 288, 365)
        d_range = st.slider("ĞŸĞµÑ€Ğ¸Ğ¾Ğ´ (Ğ´Ğ½Ğ¸)", 1, max(max_d, 2),
                             (1, min(60, max_d)))
    with cb:
        n_anom = int(anomaly_flags.sum())
        n_in   = 0
        if leaks_df is not None:
            for t in anomaly_flags[anomaly_flags].index:
                for _, lk in leaks_df.iterrows():
                    try:
                        if (pd.to_datetime(str(lk.get("Start",""))) <= t <=
                                pd.to_datetime(str(lk.get("End","")))):
                            n_in += 1
                            break
                    except Exception:
                        pass
        st.markdown(f"""
**Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ 2019:**
- Ğ’ÑĞµĞ³Ğ¾ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹: **{n_anom:,}** ÑˆĞ°Ğ³Ğ¾Ğ²
- Ğ’ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑƒÑ‚ĞµÑ‡ĞµĞº: **{n_in:,}**
- Ğ›Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³: **{n_anom - n_in:,}**
        """)

    st.plotly_chart(
        plot_pressure_with_detection(
            scada_2019, anomaly_flags, leaks_df, sensor, d_range, dark_mode
        ),
        use_container_width=True
    )

    st.markdown("---")

    # â”€â”€ Baseline vs 2019 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“Š Baseline 2018 vs ÑÑ€ĞµĞ´Ğ½ĞµĞµ 2019")
    st.caption("ĞšÑ€Ğ°ÑĞ½Ğ°Ñ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ½Ğ¸Ğ¶Ğµ ÑĞ¸Ğ½ĞµĞ¹ = ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸Ğ·-Ğ·Ğ° ÑƒÑ‚ĞµÑ‡ĞµĞº")
    st.plotly_chart(
        plot_baseline_vs_2019(baseline, scada_2019, sensor, dark_mode),
        use_container_width=True
    )

    st.markdown("---")

    # â”€â”€ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° ÑƒÑ‚ĞµÑ‡ĞµĞº â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if leaks_df is not None:
        st.markdown("### ğŸš¨ ĞšĞ°Ğ¶Ğ´Ğ°Ñ ÑƒÑ‚ĞµÑ‡ĞºĞ°: Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° / Ğ½ĞµÑ‚ / ĞºĞ¾Ğ³Ğ´Ğ° / TTD")
        rows = []
        for _, leak in leaks_df.iterrows():
            try:
                t_s = pd.to_datetime(str(leak.get("Start") or leak.get("start","")))
                t_e = pd.to_datetime(str(leak.get("End")   or leak.get("end",  "")))
            except Exception:
                continue
            w = anomaly_flags[(anomaly_flags.index >= t_s) &
                              (anomaly_flags.index <= t_e) & anomaly_flags]
            det = len(w) > 0
            rows.append({
                "Ğ£Ñ‚ĞµÑ‡ĞºĞ° #":       int(leak.get("Leak #", 0)),
                "Ğ¢Ñ€ÑƒĞ±Ğ°":          str(leak.get("Pipe","?")),
                "ĞĞ°Ñ‡Ğ°Ğ»Ğ¾":         str(t_s)[:16],
                "ĞšĞ¾Ğ½ĞµÑ†":          str(t_e)[:16],
                "Ğ Ğ°ÑÑ…Ğ¾Ğ´ (Ğ»/Ñ)":   float(leak.get("Max Flow (L/s)", 0)),
                "ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ°":     "âœ…" if det else "âŒ",
                "Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ":       w.index[0].strftime("%Y-%m-%d %H:%M") if det else "â€”",
                "TTD (Ñ‡)":        f"{max(0,(w.index[0]-t_s).total_seconds()/3600):.1f}" if det else "â€”",
            })
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        st.markdown("---")

    # â”€â”€ Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ ĞšĞ— vs L-Town â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ‡°ğŸ‡¿ L-Town (ĞšĞ¸Ğ¿Ñ€) vs ĞšĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½")
    st.dataframe(pd.DataFrame([
        {"ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€": "Ğ˜Ğ·Ğ½Ğ¾Ñ ÑĞµÑ‚ĞµĞ¹",      "L-Town": "~35%",    "ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹": "54.5%", "ĞÑÑ‚Ğ°Ğ½Ğ°": "48.0%", "Ğ¢ÑƒÑ€ĞºĞµÑÑ‚Ğ°Ğ½": "62.0%"},
        {"ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€": "Ğ¢Ğ°Ñ€Ğ¸Ñ„ (â‚¸/Ğ¼Â³)",     "L-Town": "~120",    "ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹": "91.96", "ĞÑÑ‚Ğ°Ğ½Ğ°": "85.00", "Ğ¢ÑƒÑ€ĞºĞµÑÑ‚Ğ°Ğ½": "70.00"},
        {"ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€": "Ğ”Ğ»Ğ¸Ğ½Ğ° ÑĞµÑ‚Ğ¸",        "L-Town": "42.6 ĞºĞ¼", "ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹": "3 700 ĞºĞ¼","ĞÑÑ‚Ğ°Ğ½Ğ°": "1 800 ĞºĞ¼","Ğ¢ÑƒÑ€ĞºĞµÑÑ‚Ğ°Ğ½": "600 ĞºĞ¼"},
        {"ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€": "Ğ”Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ² Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ", "L-Town": "33",      "ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹": "?",     "ĞÑÑ‚Ğ°Ğ½Ğ°": "206",   "Ğ¢ÑƒÑ€ĞºĞµÑÑ‚Ğ°Ğ½": "?"},
        {"ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€": "Ğ¨Ğ°Ğ³ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",        "L-Town": "5 Ğ¼Ğ¸Ğ½",   "ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹": "Ğ½/Ğ´",   "ĞÑÑ‚Ğ°Ğ½Ğ°": "5 Ğ¼Ğ¸Ğ½", "Ğ¢ÑƒÑ€ĞºĞµÑÑ‚Ğ°Ğ½": "Ğ½/Ğ´"},
    ]), use_container_width=True, hide_index=True)

    # â”€â”€ Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.markdown("### ğŸ† Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Astana Hub")
    with st.expander("ğŸ“‹ Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ", expanded=False):
        det_n = m.get("detected", "N")
        tot_n = m.get("total", 23)
        rec_v = m.get("recall", "?")
        prc_v = m.get("precision", "?")
        ttd_v = m.get("ttd_hours", "?")
        st.markdown(f"""
> *Â«ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Smart Shygyn PRO v3 Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ¼ĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ğ¾Ğ¼ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ
> **BattLeDIM 2020** (DOI: 10.5281/zenodo.4017659) â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞµÑ‚ÑŒ Ğ³. Ğ›Ğ¸Ğ¼Ğ°ÑÑĞ¾Ğ» (ĞšĞ¸Ğ¿Ñ€):
> 782 ÑƒĞ·Ğ»Ğ°, 909 Ñ‚Ñ€ÑƒĞ±, 42.6 ĞºĞ¼, 33 Ğ´Ğ°Ñ‚Ñ‡Ğ¸ĞºĞ° Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ.*
>
> *ĞĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… 2019 Ğ³Ğ¾Ğ´Ğ° (23 Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑƒÑ‚ĞµÑ‡ĞºĞ¸, 365 Ğ´Ğ½ĞµĞ¹ SCADA Ñ ÑˆĞ°Ğ³Ğ¾Ğ¼ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚):*
> - *ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ **{det_n} Ğ¸Ğ· {tot_n}** ÑƒÑ‚ĞµÑ‡ĞµĞº â€” Recall **{rec_v}%***
> - *Precision: **{prc_v}%***
> - *Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ: **{ttd_v} Ñ‡Ğ°ÑĞ¾Ğ²***
>
> *Ğ¢Ğ¾Ñ‚ Ğ¶Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ETH Zurich, MIT Ğ¸ Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚Ğ¾Ğ¼ ĞšĞ¸Ğ¿Ñ€Ğ°
> Ğ´Ğ»Ñ Ğ¼ĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ÑƒÑ‚ĞµÑ‡ĞµĞº.*Â»
        """)
